---
title: "P8105 HW3 jl6046"
author: "Brian Jo Hsuan Lee"
date: 2021-10-18
output: github_document
---

Import packages
```{r, message=FALSE}
library(tidyverse)
library(httr)
library(jsonlite)
library(patchwork)
library(p8105.datasets)
```

Set knitr options
```{r}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

##Problem 1: Instacart Purchases

The instacart dataset shows purchase records labeled with buyers, time, and other relevant identifiers, such as aisle and department. It has 1384617 observations and 15 variables, with a purchased item on each row. For example, we could see that a customer bought a Bulgarian yogurt from the yogurt aisle in the dairy department and a Cucumber Kirby from the fresh vegetables aisle in the produce department on the same day.
```{r}
data("instacart")
str(instacart)
```

There are 134 distinct aisles in the data set.
```{r}
aisle_count = 
  instacart %>% 
  select(aisle) %>% 
  distinct()

aisle_count
```

And among them, the 'fresh vegetables', 'fresh fruits', and 'packaged vegetables fruits' were the most popular aisles from which items were bought.
```{r}
aisle_pop = 
  instacart %>% 
  mutate(count = 1) %>% 
  aggregate(count ~ aisle, data = ., sum) %>% 
  arrange(desc(count))

head(aisle_pop, 5)
```

With fresh vegetables and fresh fruits surpassing 150 thousand purchases, see the other 47 popular aisles with over 10 thousand purchases. 
```{r}
aisle_pop %>% 
  filter(count > 10000) %>% 
  mutate(
    aisle_ord = factor(aisle),
    aisle_ord = forcats::fct_reorder(aisle_ord, count, .desc = TRUE)
  ) %>% 
  ggplot(., aes(x = aisle_ord, y = count, fill = aisle)) +
  geom_bar(stat="identity") +
  labs(
    title = "Most Popular Aisles",
    x = "Item Count",
    y = "Aisle"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(hjust = 1, angle = 90),
    legend.position = "none",
    legend.title = element_blank(),
    legend.key.size = unit(0.5, 'cm'),
    legend.text = element_text(size = 5)
  )
```

The following table shows the number of purchases for each of the 3 most popular items from aisles "baking ingredients", "dog food care", and "pacakged vegetables".
```{r, message=FALSE}
bi_pop =
  instacart %>%
  select(aisle, product_name) %>% 
  filter(aisle == "baking ingredients") %>%
  group_by(aisle, product_name) %>% 
  summarize(count = n()) %>% 
  arrange(desc(count)) %>% 
  slice(1:3) %>% 
  ungroup()

dfc_pop =
  instacart %>%
  select(aisle, product_name) %>% 
  filter(aisle == "dog food care") %>%
  group_by(aisle, product_name) %>% 
  summarize(count = n()) %>% 
  arrange(desc(count)) %>% 
  slice(1:3) %>% 
  ungroup()

pvf_pop =
  instacart %>%
  select(aisle, product_name) %>% 
  filter(aisle == "packaged vegetables fruits") %>%
  group_by(aisle, product_name) %>% 
  summarize(count = n()) %>% 
  arrange(desc(count)) %>% 
  slice(1:3) %>% 
  ungroup()

item_pop = 
  bind_rows(bi_pop, dfc_pop, pvf_pop)

item_pop
```

The following is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.
```{r, message=FALSE, warning=FALSE}
aic_week =
  instacart %>% 
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(order_dow, order_hour_of_day, product_name) %>% 
  mutate(
    order_dow = recode(order_dow, `0` = "sunday", `1` = "monday", `2` = "tuesday", `3` = "wednesday", `4` = "thursday", `5` = "friday", `6` = "saturday")
  ) %>% 
  group_by(order_dow, product_name) %>% 
  summarize(mean_hour = mean(order_hour_of_day, )) %>% 
  mutate(
    mean_hour = round(mean_hour, 1)
  ) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  select(product_name, sunday, monday, tuesday, wednesday, thursday, friday, saturday) %>% 
  ungroup()

aic_week
```

## Problem 2: BRFSS

Load and clean up the BRFSS data set for this problem
```{r, warning=FALSE}
data("brfss_smart2010")

brfss_df = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health", response == c("Excellent", "Very Good", "Good", "Fair", "Poor")) %>% 
  mutate(
    response = factor(response, levels = c("Excellent", "Very Good", "Good", "Fair", "Poor"))
  )
```


Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).
Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

No states had observations from more than 7 locations in 2002, but Florida achieved that number in 2010. 
```{r, warning=FALSE, message=FALSE}
more_than_7_df = 
  brfss_df %>% 
  filter(year == c(2002, 2010)) %>% 
  select(year, locationabbr, locationdesc) %>% 
  distinct() %>% 
  group_by(year, locationabbr) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  pivot_wider(
    names_from = year,
    values_from = count
  ) %>% 
  mutate(
    `>7_in_2002` = `2002` > 7,
    `>7_in_2010` = `2010` > 7
  ) %>% 
  select(locationabbr, `>7_in_2002`, `>7_in_2010`) %>% 
  arrange(locationabbr)

more_than_7_df
```

```{r}

```

